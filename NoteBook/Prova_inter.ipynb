{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b745e75d-a1bd-4041-bb8c-72cc9c57a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import numpy as np\n",
    "import scipy \n",
    "import matplotlib as mpl\n",
    "import PyQt5\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "os.chdir('../')\n",
    "from AllPackage import *\n",
    "from AllPackage.Data.PreProcessing import *\n",
    "from AllPackage.Data.MakeData import *\n",
    "from AllPackage.Cluster import *\n",
    "os.chdir('./NoteBook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ee7916c5-a033-4570-8d2e-f5fe8e9bccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS1b = pd.DataFrame(build_S11x11_df(initial_path='../Data/Raw/S_11x11',final_path='../Data/Initial/S_11x11')[0])\n",
    "dfS1 = pd.DataFrame(build_S11x11_df(initial_path='../Data/Raw/S_11x11',final_path='../Data/Initial/S_11x11')[1])\n",
    "dfS2 = pd.DataFrame(build_S11x11_df(initial_path='../Data/Raw/S_11x11',final_path='../Data/Initial/S_11x11')[2])\n",
    "dfS2b = pd.DataFrame(build_S11x11_df(initial_path='../Data/Raw/S_11x11',final_path='../Data/Initial/S_11x11')[3])\n",
    "l_df = [dfS1b,dfS1,dfS2b,dfS2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5407ce0f-86fb-446d-982e-9551df276a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.8228\\ 4000.292\n"
     ]
    }
   ],
   "source": [
    "    #cerchiamo il range dei picchi per capire dove ha senso fare il binning\n",
    "\n",
    "minw = []\n",
    "maxw = []\n",
    "for i in range(len(l_df)):\n",
    "    picchi_wn = trova_picchi(l_df[i],l_df[i].columns)\n",
    "    picchi_wn = [x for x in picchi_wn[0] if(len(x)>=3)] #rimuovo spettri senza picchi\n",
    "    picchioledonne = range_picchi(picchi_wn)\n",
    "    minw.append(min(([min(x) for x in picchioledonne])))\n",
    "    maxw.append(max(([max(x) for x in picchioledonne])))\n",
    "minw = min(minw)\n",
    "maxw = max(maxw)\n",
    "print(str(minw)+'\\ '+str(maxw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184ba9f-e8da-4b5b-8ba3-b2ac11335cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_width = 10\n",
    "bin_count = 0\n",
    "bin_values = []\n",
    "for x in dfS1b.index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3f20c40f-3ab7-482a-a642-2585f46745fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mdfS1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return cumulative sum over a DataFrame or Series axis.\n",
       "\n",
       "Returns a DataFrame or Series of the same size containing the cumulative\n",
       "sum.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
       "    The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
       "skipna : bool, default True\n",
       "    Exclude NA/null values. If an entire row/column is NA, the result\n",
       "    will be NA.\n",
       "*args, **kwargs\n",
       "    Additional keywords have no effect but might be accepted for\n",
       "    compatibility with NumPy.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "Series or DataFrame\n",
       "    Return cumulative sum of Series or DataFrame.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "core.window.Expanding.sum : Similar functionality\n",
       "    but ignores ``NaN`` values.\n",
       "DataFrame.sum : Return the sum over\n",
       "    DataFrame axis.\n",
       "DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
       "DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
       "DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
       "DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "**Series**\n",
       "\n",
       ">>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
       ">>> s\n",
       "0    2.0\n",
       "1    NaN\n",
       "2    5.0\n",
       "3   -1.0\n",
       "4    0.0\n",
       "dtype: float64\n",
       "\n",
       "By default, NA values are ignored.\n",
       "\n",
       ">>> s.cumsum()\n",
       "0    2.0\n",
       "1    NaN\n",
       "2    7.0\n",
       "3    6.0\n",
       "4    6.0\n",
       "dtype: float64\n",
       "\n",
       "To include NA values in the operation, use ``skipna=False``\n",
       "\n",
       ">>> s.cumsum(skipna=False)\n",
       "0    2.0\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "dtype: float64\n",
       "\n",
       "**DataFrame**\n",
       "\n",
       ">>> df = pd.DataFrame([[2.0, 1.0],\n",
       "...                    [3.0, np.nan],\n",
       "...                    [1.0, 0.0]],\n",
       "...                    columns=list('AB'))\n",
       ">>> df\n",
       "     A    B\n",
       "0  2.0  1.0\n",
       "1  3.0  NaN\n",
       "2  1.0  0.0\n",
       "\n",
       "By default, iterates over rows and finds the sum\n",
       "in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
       "\n",
       ">>> df.cumsum()\n",
       "     A    B\n",
       "0  2.0  1.0\n",
       "1  5.0  NaN\n",
       "2  6.0  1.0\n",
       "\n",
       "To iterate over columns and find the sum in each row,\n",
       "use ``axis=1``\n",
       "\n",
       ">>> df.cumsum(axis=1)\n",
       "     A    B\n",
       "0  2.0  3.0\n",
       "1  3.0  NaN\n",
       "2  1.0  1.0\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/envDS/lib/python3.10/site-packages/pandas/core/generic.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    dfS1.cumsum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "08cafa11-fb71-46dc-bb28-96c7b467ad08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000.292"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd64534c-8053-45f9-a318-ba5573f1ee48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
